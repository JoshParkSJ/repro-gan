{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02bb21e-174a-4a8b-9911-b78874fae08d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './examples/test_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m h\n\u001b[0;32m     57\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./examples/test_data.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;66;03m# torch.Size([2, 64, 3152])\u001b[39;00m\n\u001b[0;32m     59\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     60\u001b[0m     TensorDataset(data),\n\u001b[0;32m     61\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     62\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m netD \u001b[38;5;241m=\u001b[39m Discriminator()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\joshua.park\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './examples/test_data.npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from repro_gan.models.wgan_gp import WGANGPBaseDiscriminator, WGANGPBaseGenerator\n",
    "from repro_gan.training import Trainer\n",
    "from repro_gan.modules import DBlock, GBlock\n",
    "\n",
    "class Discriminator(WGANGPBaseDiscriminator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(channels=64)\n",
    "\n",
    "        self.block1 = DBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, downsample=True)\n",
    "        self.block2 = DBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, downsample=True)\n",
    "        self.block3 = DBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, downsample=True)\n",
    "        self.conv = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
    "        self.end = nn.Linear(394, 1)\n",
    "        \n",
    "        nn.init.normal_(self.conv.weight.data, 0.0, 0.02)\n",
    "        nn.init.normal_(self.end.weight.data, 0.0, 0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h = self.block1(x)\n",
    "        h = self.block2(h)\n",
    "        h = self.block3(h)\n",
    "        h = self.conv(h)\n",
    "        h = self.end(h)\n",
    "        return h.view(h.shape[0], 64)\n",
    "\n",
    "class Generator(WGANGPBaseGenerator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(channels=64, nz=3152) # noise shape will start off as real_data.shape[0] x channels x nz\n",
    "\n",
    "        # Build the layers\n",
    "        self.block1 = GBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, upsample=False)\n",
    "        self.block2 = GBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, upsample=False)\n",
    "        self.block3 = GBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, upsample=False)\n",
    "        self.conv = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        # Initialise the weights\n",
    "        nn.init.normal_(self.conv.weight.data, 0.0, 0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h = self.block1(x)\n",
    "        h = self.block2(h)\n",
    "        h = self.block3(h)\n",
    "        h = self.conv(h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.tensor(np.load(\"./test_data.npy\")).detach() # torch.Size([2, 64, 3152])\n",
    "dataloader = DataLoader(\n",
    "    TensorDataset(data),\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netG = Generator().to(device)\n",
    "\n",
    "optD = optim.Adam(netD.parameters(), 0.0001, (0.5, 0.99))\n",
    "optG = optim.Adam(netG.parameters(), 0.0001, (0.5, 0.99))\n",
    "\n",
    "trainer = Trainer(\n",
    "    netD=netD, # netD=netD.module to use GPU\n",
    "    netG=netG, # netD=netD        to use CPU\n",
    "    optD=optD,\n",
    "    optG=optG,\n",
    "    n_dis=1,\n",
    "    num_steps=3,\n",
    "    dataloader=dataloader,\n",
    "    save_steps=1,\n",
    "    print_steps=1,\n",
    "    log_steps=1,\n",
    "    log_dir='./examples/logs',\n",
    "    device=device)\n",
    "trainer.train()\n",
    "\n",
    "# tensorboard --logdir=./examples/logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a8a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
